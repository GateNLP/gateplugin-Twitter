Phase: TwitterTokens
Input: Token SpaceToken Lookup URL Hashtag UserMention Symbol
Options: control = appelt


// Make use of existing Hashtag annotations
Rule: JSONHashtag
Priority:1000
(
  {Hashtag}
):match
-->
:match {
	Annotation hashtag = matchAnnots.iterator().next();
	FeatureMap features = hashtag.getFeatures();

	features.put("string", gate.Utils.cleanStringFor(doc, matchAnnots));
	features.put("length", (int)(matchAnnots.lastNode().getOffset() - matchAnnots.firstNode().getOffset()));

}

Rule:JSONSymbol
Priority:1000
(
  {Symbol}
):match
-->
:match {
  Annotation symbol = matchAnnots.iterator().next();
  AnnotationSet tokens = gate.Utils.getContainedAnnotations(inputAS, matchAnnots, "Token");

   FeatureMap newtok = Factory.newFeatureMap();
   newtok.put("rule", "JSONSymbol");
   newtok.put("category", "SYM");
   newtok.put("kind", "word");
   newtok.put("length", (int)(matchAnnots.lastNode().getOffset() - matchAnnots.firstNode().getOffset()));
   newtok.put("string", gate.Utils.cleanStringFor(doc, matchAnnots));
   gate.Utils.addAnn(outputAS,matchAnnots,"Token",newtok);

   inputAS.removeAll(tokens);
}

// Make use of existing @mentions
Rule: JSONUserMention
Priority:1000
(
  {UserMention}
):match
-->
:match {
   Annotation userMention = matchAnnots.iterator().next();
   AnnotationSet tokens = gate.Utils.getContainedAnnotations(inputAS, matchAnnots, "Token");

   FeatureMap mentionFeatures = userMention.getFeatures();
   mentionFeatures.put("replaced",tokens.size());
   mentionFeatures.put("length", (int)(matchAnnots.lastNode().getOffset() - matchAnnots.firstNode().getOffset()));
   mentionFeatures.put("string", gate.Utils.cleanStringFor(doc, matchAnnots));
   mentionFeatures.put("user",mentionFeatures.remove("screen_name"));

   FeatureMap idFeatures = Factory.newFeatureMap();
   idFeatures.putAll(mentionFeatures);
   idFeatures.put("length", (int)(matchAnnots.lastNode().getOffset() - matchAnnots.firstNode().getOffset())-1);
   idFeatures.put("string", gate.Utils.cleanStringFor(doc, matchAnnots).substring(1));
   gate.Utils.addAnn(outputAS,matchAnnots.firstNode().getOffset()+1,matchAnnots.lastNode().getOffset(),"UserID",idFeatures);

   // add new token for user id string
   FeatureMap newtok = Factory.newFeatureMap();
   newtok.put("rule", "JSONUserMention");
   newtok.put("category", "USR");
   newtok.put("kind", "word");
   newtok.put("length", (int)(matchAnnots.lastNode().getOffset() - matchAnnots.firstNode().getOffset()));
   newtok.put("string", gate.Utils.cleanStringFor(doc, matchAnnots));
   gate.Utils.addAnn(outputAS,matchAnnots,"Token",newtok);

   inputAS.removeAll(tokens);
}

// Make use of existing URLs
Rule: JsonURLandMedia
Priority:1000
(
  {URL}
):match
-->
:match {
   FeatureMap newf = Factory.newFeatureMap();
   newf.put("rule", "JsonURLandMedia");
   newf.put("category", "URL");
   newf.put("kind", "URL");
   newf.put("length", (int)(matchAnnots.lastNode().getOffset()-matchAnnots.firstNode().getOffset()));
   newf.put("string", gate.Utils.cleanStringFor(doc, matchAnnots));

   AnnotationSet tokens = gate.Utils.getContainedAnnotations(inputAS, matchAnnots, "Token");

   gate.Utils.addAnn(outputAS,matchAnnots,"Token",newf);

   inputAS.removeAll(tokens);
}

Rule:Symbol
(
	{Token.string == "$"}
	{Token.kind == "word", Token.length <= 6}
	(
		({Token.string == "."}|{Token.string == "_"})
		{Token.kind == "word", Token.length <= 2}
	)?
):match
-->
:match {
   AnnotationSet tokens = gate.Utils.getContainedAnnotations(inputAS, matchAnnots, "Token");

   FeatureMap newtok = Factory.newFeatureMap();
   newtok.put("rule", "Symbol");
   newtok.put("category", "SYM");
   newtok.put("kind", "word");
   newtok.put("length", (int)(matchAnnots.lastNode().getOffset() - matchAnnots.firstNode().getOffset()));
   newtok.put("string", gate.Utils.cleanStringFor(doc, matchAnnots));
   gate.Utils.addAnn(outputAS,matchAnnots,"Token",newtok);

   inputAS.removeAll(tokens);

   FeatureMap symbol = Factory.newFeatureMap();
   symbol.put("text", gate.Utils.cleanStringFor(doc, matchAnnots).substring(1));
   gate.Utils.addAnn(outputAS,matchAnnots,"Symbol",symbol);
}


// now find everything else!

Macro: URL_START
(
 // TODO: add more URL shortening services
 ( ( {Token.string == "http"} | {Token.string == "https"} | {Token.string == "ftp"} )
   {Token.string == ":"} {Token.string == "/"} {Token.string == "/"} )
 |
 ({Token.kind == "word"} {Token.string == "."}{Token.kind == "word"}{Token.string == "/"})
)


// Syntax of usernames
// http://sentiment.christopherpotts.net/tokenizing.html#twitter
// @+[\w_]+

// and hashtags according to
// https://support.twitter.com/articles/370610-my-hashtags-or-replies-aren-t-working
// can include numbers but can't be just a number
// punctuation breaks the tag; apart from underscores appear to be allowed

Rule: Hashtag
( {Token.string == "#"}
  ({Token.kind == "number"})?
  ({Token.kind=="word"}|{Token.string == "_"})
  ({Token.kind=="word"}|{Token.kind=="number"}|{Token.string == "_"})[0,10]
): match
-->
:match {
   long start = matchAnnots.firstNode().getOffset();
   long end = matchAnnots.lastNode().getOffset();

   // add spanning annotation
   FeatureMap htag = Factory.newFeatureMap();
   htag.put("rule", "Hashtag");
   htag.put("kind", "Hashtag");
   htag.put("length", (int) end - start);
   String string = gate.Utils.cleanStringFor(doc, matchAnnots);
   htag.put("string", string);

   try {
    outputAS.add(start, end, "Hashtag", htag);
   }
   catch (InvalidOffsetException e) {
    e.printStackTrace();
   }

}


// combine non-space-separated lowercase words and numbers (e.g. |gr|8| -> |gr8|, |2|day| -> |2day|) - in preparation for norm
Rule: Recombine
( ({Token.kind == "word", Token.orth == "lowercase"} {Token.kind == "number"}) |
  ({Token.kind == "number"} {Token.kind == "word", Token.orth == "lowercase"})
):match
-->
:match {
   long start = matchAnnots.firstNode().getOffset();
   long end = matchAnnots.lastNode().getOffset();

   FeatureMap tok = Factory.newFeatureMap();
   tok.put("rule", "Recombine");
   tok.put("kind", "word");
   tok.put("length", (int) end - start);
   String string = gate.Utils.cleanStringFor(doc, matchAnnots);
   tok.put("string", string);
   tok.put("orth", "mixed");

   // remove prior annotations
   AnnotationSet tokens = gate.Utils.getContainedAnnotations(inputAS, matchAnnots, "Token");
   tok.put("replaced", tokens.size());
   inputAS.removeAll(tokens);

   // add spanning annotation
   try {
    outputAS.add(start, end, "Token", tok);
   }
   catch (InvalidOffsetException e) {
    e.printStackTrace();
   }
}

Rule: NotRecombineEmoticon
Priority: 100
/* Do not recombine emoticon if it's preceded directly by a number, as it's probably not an emoticon, e.g. 8:30 */
(
 {Token.kind == number}
 {Lookup.majorType=="emoticon"}
 )
 -->
 {}
 
 
 Rule: RecombineEmoticon
(
	{Lookup.majorType=="emoticon"}
):match
-->
:match {
   long start = matchAnnots.firstNode().getOffset();
   long end = matchAnnots.lastNode().getOffset();

   FeatureMap tok = Factory.newFeatureMap();
   tok.put("rule", "RecombineEmoticon");
   tok.put("kind", "punctuation");
   tok.put("category", "UH");
   tok.put("length", (int) end - start);
   tok.put("origString", gate.Utils.cleanStringFor(doc, matchAnnots));
   tok.put("string", matchAnnots.iterator().next().getFeatures().get("normalized"));
   tok.put("orth", "mixed");

   // remove prior annotations
   AnnotationSet tokens = gate.Utils.getContainedAnnotations(inputAS, matchAnnots, "Token");
   tok.put("replaced", tokens.size());
   inputAS.removeAll(tokens);

   // add spanning annotation
   try {
    outputAS.add(start, end, "Token", tok);
   }
   catch (InvalidOffsetException e) {
    e.printStackTrace();
   }
   
   FeatureMap params = Factory.newFeatureMap();
   params.put("normalized", matchAnnots.iterator().next().getFeatures().get("normalized"));
   try {
    outputAS.add(start, end, "Emoticon", params);
   }
   catch (InvalidOffsetException e) {
    e.printStackTrace();
   }
}

Rule: UserID
( ({Token.string == "@"})
  (({Token.kind=="word"} | {Token.kind=="number"} | {Token.string=="_"})[1,5]):handle
): match
-->
:match {
   // get boundaries of @userid
   long start = matchAnnots.firstNode().getOffset();
   long end = matchAnnots.lastNode().getOffset();

   AnnotationSet handleAnnots = bindings.get("handle");

   // build new UserID annotation
   FeatureMap userid = Factory.newFeatureMap();
   userid.put("rule", "UserID");
   userid.put("kind", "UserID");
   userid.put("length", (int)(handleAnnots.lastNode().getOffset() - handleAnnots.firstNode().getOffset()));
   String handle = gate.Utils.cleanStringFor(doc, handleAnnots);
   userid.put("string", handle);
   userid.put("user", handle);
   userid.put("replaced", matchAnnots.size());
   gate.Utils.addAnn(outputAS,handleAnnots,"UserID",userid);

   // build new UserMention annotation
   FeatureMap userMention = Factory.newFeatureMap();
   userMention.put("rule", "UserID");
   userMention.put("kind", "UserMention");
   userMention.put("length", (int)(matchAnnots.lastNode().getOffset() - matchAnnots.firstNode().getOffset()));
   userMention.put("string", gate.Utils.cleanStringFor(doc, matchAnnots));
   userMention.put("user", handle);
   userMention.put("replaced", matchAnnots.size());
   gate.Utils.addAnn(outputAS,matchAnnots,"UserMention",userMention);

   // add new token for user id string
   FeatureMap newtok = Factory.newFeatureMap();
   newtok.put("rule", "UserID");
   newtok.put("category", "USR");
   newtok.put("kind", "word");
   newtok.put("length", (int)(matchAnnots.lastNode().getOffset() - matchAnnots.firstNode().getOffset()));
   newtok.put("string", gate.Utils.cleanStringFor(doc, matchAnnots));
   gate.Utils.addAnn(outputAS,matchAnnots,"Token",newtok);

   inputAS.removeAll(matchAnnots);
}


// TODO: restrict to syntactically valid URLs?

Rule: URL
((URL_START)
 ({Token.string !=~ "[\"â€\']"})[1,20]
): match
-->
:match {
   long start = matchAnnots.firstNode().getOffset();
   long end = matchAnnots.lastNode().getOffset();

   FeatureMap newf = Factory.newFeatureMap();
   newf.put("rule", "URL");
   newf.put("category", "URL");
   newf.put("kind", "URL");
   newf.put("length", (int) end - start);
   String string = gate.Utils.cleanStringFor(doc, matchAnnots);
   newf.put("string", string);
   
   FeatureMap newuf = Factory.newFeatureMap();
   newuf.put("url",string);

   {
     AnnotationSet tokens = gate.Utils.getContainedAnnotations(inputAS, matchAnnots, "Token");
     newf.put("replaced", tokens.size());
     inputAS.removeAll(tokens);
   }
  
   try {
     outputAS.add(start, end, "Token", newf);
     outputAS.add(start, end, "URL", newuf);
   }
   catch (InvalidOffsetException e) {
     e.printStackTrace();
   }
}


Rule: Separator
( ( ({Token.string=="<"})[2,9] )
  |
  ( ({Token.string==">"})[2,9] )
): match
-->
:match {
   long start = matchAnnots.firstNode().getOffset();
   long end = matchAnnots.lastNode().getOffset();

   FeatureMap newf = Factory.newFeatureMap();
   newf.put("rule", "Separator");
   newf.put("temp_category", "SYM");
   newf.put("kind", "separator");
   newf.put("length", (int) end - start);
   String string = gate.Utils.cleanStringFor(doc, matchAnnots);
   newf.put("string", string);

   {
     AnnotationSet tokens = gate.Utils.getContainedAnnotations(inputAS, matchAnnots, "Token");
     newf.put("replaced", tokens.size());
     inputAS.removeAll(tokens);
   }
  
   try {
     outputAS.add(start, end, "Token", newf);
   }
   catch (InvalidOffsetException e) {
     e.printStackTrace();
   }
}

